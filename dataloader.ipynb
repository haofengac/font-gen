{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from fastai.vision import *\n",
    "from pathlib import Path\n",
    "import pdb\n",
    "import re\n",
    "import seaborn as sns\n",
    "from IPython.display import SVG, display\n",
    "from wand.image import Image as WImage\n",
    "import wand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../google-fonts-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='113646' class='' max='113646', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [113646/113646 00:05<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = []\n",
    "for file in progress_bar(path.glob(\"**/*.svg\"),total=113646):\n",
    "    try:\n",
    "        match = re.match(\".*viewBox=\\\"0 0 (\\d+) (\\d+)\\\".*<path.*d=\\\"([^\\\"]*)\\\".*\",file.open().read(),flags=re.DOTALL)\n",
    "        out.append({\"file\": file, \"path\": match.group(3), \"box_x\": float(match.group(1)), \"box_y\": float(match.group(2))})\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>box_x</th>\n",
       "      <th>box_y</th>\n",
       "      <th>file</th>\n",
       "      <th>path</th>\n",
       "      <th>png</th>\n",
       "      <th>label</th>\n",
       "      <th>font</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>535.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>M32 34q0 10 1 16l2 17q3 27 11.5 38.5t24.5 11.5...</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>one</td>\n",
       "      <td>asap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>843.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>M57 6.5q-13 8.5 -11 28.5l66 635q3 32 63 32h52q...</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>$M</td>\n",
       "      <td>asap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>M15.5 24.5q-8.5 24.5 -8.5 48.5q0 15 8 24l257 3...</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>z</td>\n",
       "      <td>asap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>731.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>M493.5 -105.5q-133.5 56.5 -258.5 112.5q-97 44 ...</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>$Q</td>\n",
       "      <td>asap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>549.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>M174 35l56 534h-158q-14 0 -20.5 9.5t-6.5 31.5q...</td>\n",
       "      <td>../google-fonts-data/italic/SANS_SERIF/asap/70...</td>\n",
       "      <td>$T</td>\n",
       "      <td>asap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   box_x   box_y                                               file  \\\n",
       "0  535.0  1000.0  ../google-fonts-data/italic/SANS_SERIF/asap/70...   \n",
       "1  843.0  1000.0  ../google-fonts-data/italic/SANS_SERIF/asap/70...   \n",
       "2  489.0  1000.0  ../google-fonts-data/italic/SANS_SERIF/asap/70...   \n",
       "3  731.0  1000.0  ../google-fonts-data/italic/SANS_SERIF/asap/70...   \n",
       "4  549.0  1000.0  ../google-fonts-data/italic/SANS_SERIF/asap/70...   \n",
       "\n",
       "                                                path  \\\n",
       "0  M32 34q0 10 1 16l2 17q3 27 11.5 38.5t24.5 11.5...   \n",
       "1  M57 6.5q-13 8.5 -11 28.5l66 635q3 32 63 32h52q...   \n",
       "2  M15.5 24.5q-8.5 24.5 -8.5 48.5q0 15 8 24l257 3...   \n",
       "3  M493.5 -105.5q-133.5 56.5 -258.5 112.5q-97 44 ...   \n",
       "4  M174 35l56 534h-158q-14 0 -20.5 9.5t-6.5 31.5q...   \n",
       "\n",
       "                                                 png label  font  \n",
       "0  ../google-fonts-data/italic/SANS_SERIF/asap/70...   one  asap  \n",
       "1  ../google-fonts-data/italic/SANS_SERIF/asap/70...    $M  asap  \n",
       "2  ../google-fonts-data/italic/SANS_SERIF/asap/70...     z  asap  \n",
       "3  ../google-fonts-data/italic/SANS_SERIF/asap/70...    $Q  asap  \n",
       "4  ../google-fonts-data/italic/SANS_SERIF/asap/70...    $T  asap  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svgDF = pd.DataFrame(out)\n",
    "svgDF[\"png\"] = svgDF.file.apply(lambda f: \"/\".join(f.parts[:-2]) + \"/png/\" + f.name[:-3] + \"png\")\n",
    "exists = svgDF.png.apply(lambda f: Path(f).exists())\n",
    "svgDF[\"label\"] = svgDF.file.apply(lambda f: f.name[:-4])\n",
    "svgDF[\"font\"] = svgDF.file.apply(lambda f: f.parts[4])\n",
    "svgDF = svgDF[exists]\n",
    "svgDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_path(path,bbox_x,bbox_y):\n",
    "    bbox_x,bbox_y = int(bbox_x),int(bbox_y)\n",
    "    st = f'<svg viewBox=\"0 0 {bbox_x} {bbox_y}\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"{path}\"/></svg>'\n",
    "    img = WImage(blob=str.encode(st),format=\"svg\",width=128,height=128)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAQAAABpN6lAAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QAAKqNIzIAAAAHdElNRQfjCAgSFS8qBgzxAAAD8UlEQVR42u2cS0hUURzGP8c3omYPU9HMdKbAwBZhD3ovyjJIKtrVsnDTsiDIok3LdhGtLFoUJIQiVJRFRUFGYESEBKEW9iKtyEpL20nljN075zsv5/+7q7kz95v/+ebMd8+999wLxKMWpzHh/fIIR1GB0KSjy3rpzOUu8qdrbtqUNW3YGd41xynAl+AGTNiuVgPdqE9tA4A6PIn/RsR2ZYZoSfRGqvSAeC0FkDo9ACgMasB125VqYnlQAy7brlQTu4Ma0GG7Uk3UBjXgje1KNREiBFfYrlULt+OvTo+z7jUysM52vXSa8D3Mx/daP4jhLkn16gZcsF64+tKBXdM1Mi2oG0lThI8kpTyM8MvTPxIcpikt0VGefgN4xxabdJSXri7xX2ZhJUUnG60GqtXAFlqgacDE0eBjmlKunwZ8oClF/TTA6Rg0EYJAaaKj8ZBk4ryReunscDcGzZwSe0hTyvHTgLc0pWo/DRinKW300wDgHEmn0VC9dPa4GoOmesADmlK2nwYM0pSq/DTgJ01pvZ8GAJdIOtuNVUxmn5sxaK4H3KMpZflpwABNqdJPA8ZoStSLNibnB7STdLwdDe53MQZN9oA7NKVMPw14SVNKYv6nCwb8oCmt9dMA3vwjb2PwoHsxaLYH3KIpZfhpwAuaUrmfBnyjKa320wDeWMDbGDzkWgya7gE3aUqki3qmDXhOUyrz04CvNKVVfhrAu07obQy2uBWD5nvADZoSJQbNG/CUplTipwGfaUqUWe027hnqIelss1A7hZMuxaCNHnCNpkSo3ue/AFDspwHDNKV6dQkbBvBOaHkbg6fciUE7t85epSkp12/HAN788bl+GsCbP648B9mOAbwY3KoqEP6usXIcQfPkq24MoB99GMAg3mEIIxjFrwAqZ3CAZIHifW9hNz+G4wE/eR/96EM/XmEQ7/EJIxj7Y8rsDlwhGRDhT55MTDNl19WFVpyg7QiVYzA42bSimctmtUaFCcEmc16HQDkGg9Nu/dfWMBoME4KuPl9GKQZnwlNkilQ2ngkGLEt1AxpMGdBmu6UJUDorEMaAVtstTUCtynA4zKaRQKN8GxQlf5otTA8Yx2LbLU1AXfKbhgvBXqShEZ222zsFheFw8v+eXMxBKSpRgxiiWGPVgJ7kd4XMp8hEkIUCzMcCVCOGqOphipl26H6MThoykYd5KEcVYoihBkvdMoA24zIBExjFKIbQ+8+35mI2yrAQUcQQVb7AoTBbRP+DlIISQQ4KUTKZKhsCbncWh1WuNbljQPzqspCPYlRgEWKI/TXme4ZOXCSeYBcEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQZiJ/AZHXE0msw20rwAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxOS0wOC0wOFQxODoyMTo0NyswMDowMJ/vT1UAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTktMDgtMDhUMTg6MjE6NDcrMDA6MDDusvfpAAAASnRFWHRzaWduYXR1cmUAOGRhN2UzNDIxMGEzZDM2ZmM4YTg2YTlhMjdiM2M5MzI3MDZkYTMzNjM5ZTViNGE0NjBkYjMzMmVlM2MwNjM4NDsLuJEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<wand.image.Image: 8da7e34 'SVG' (128x128)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = svgDF.iloc[0]\n",
    "render_path(r.path,r.box_x,r.box_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_dict = {\"P\": [], \"M\": [\"x\",\"y\"], \"m\": [\"x\",\"y\"], \"L\": [\"x\",\"y\"], \"l\": [\"x\",\"y\"], \"H\": [\"x\"], \"h\": [\"x\"], \n",
    "             \"V\": [\"y\"], \"v\": [\"y\"], \"C\": [\"x\",\"y\",\"x\",\"y\",\"x\",\"y\"], \"c\": [\"x\",\"y\",\"x\",\"y\",\"x\",\"y\"], \"S\": [\"x\",\"y\",\"x\",\"y\"], \n",
    "             \"s\": [\"x\",\"y\",\"x\",\"y\"], \"Q\": [\"x\",\"y\",\"x\",\"y\"], \"q\": [\"x\",\"y\",\"x\",\"y\"], \"T\": [\"x\",\"y\"], \"t\": [\"x\",\"y\"],\n",
    "             \"A\": [\"x\",\"y\",\"\",\"\",\"\",\"x\",\"y\"], \"a\": [\"x\",\"y\",\"\",\"\",\"\",\"x\",\"y\"], \"Z\": [], \"z\": [], \"START\": [], \"END\": [], \"PAD\": []}\n",
    "\n",
    "\n",
    "class TokenizeSVGProcessor(PreProcessor):\n",
    "    \n",
    "    def tokenize(self,path,box_x,box_y,label):\n",
    "        out = []\n",
    "        for match in re.findall(\"([MmLlHhVvCcSsQqTtAaZz])([0-9\\.\\-\\s]*)\",path):\n",
    "            token, pen = match\n",
    "            td = tool_dict[token]\n",
    "            xs = []\n",
    "            for coord,x in zip(td,re.findall(\"((\\-{0,1}\\.[0-9]+)|(\\-{0,1}[0-9]+\\.{0,1}[0-9]*))\\s*\",pen)):\n",
    "                x = x[0]\n",
    "                try:\n",
    "                    if coord == \"x\":\n",
    "                        xs.append(float(x)/box_x)\n",
    "                    elif coord == \"y\":\n",
    "                        xs.append(float(x)/box_y)\n",
    "                    else:\n",
    "                        xs.append(float(x))\n",
    "                except:\n",
    "                    xs.append(0.0)\n",
    "            assert len(td) == 0 or (len(xs) % len(td) == 0)\n",
    "            if len(td) == 0:\n",
    "                out.append((token,[-2.0]*7))\n",
    "            else:\n",
    "                for i in range(0,len(xs),len(td)):\n",
    "                    s = xs[i:i+len(td)]\n",
    "                    if len(s) < 7: s += [-2.0] * (7-len(s))\n",
    "                    out.append((token,s))\n",
    "        return out,label\n",
    "    \n",
    "    def process(self, ds):\n",
    "        ds.items = array([self.process_one(item) for item in ds.items])\n",
    "\n",
    "    def process_one(self, item):\n",
    "        return self.tokenize(*item)\n",
    "    \n",
    "class NumericalizeSVGProcessor(PreProcessor):\n",
    "    def process_one(self,item):\n",
    "        item,label = item\n",
    "        return [(self.stoi[\"START\"],[-2.0]*7)] + [(self.stoi[t],n) for t,n in item] + [(self.stoi[\"END\"],[-2.0]*7)],label\n",
    "            \n",
    "    def process(self,ds):\n",
    "        if not hasattr(self,\"vocab\"):\n",
    "            vocab = [\"PAD\"] + list(\"Mqlthzv\") + [\"START\",\"END\"]\n",
    "            stoi = {s:i for i,s in enumerate(vocab)}\n",
    "            self.vocab = ds.vocab = vocab\n",
    "            self.stoi = ds.stoi = stoi\n",
    "        super().process(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGList(ItemList):\n",
    "    _processor = [TokenizeSVGProcessor,NumericalizeSVGProcessor]\n",
    "    \n",
    "    def get(self, i):\n",
    "        item = self.items[i]\n",
    "        item,label = item\n",
    "        return [t[0] for t in item], np.stack([t[1] for t in item]), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npad_collate(samples:BatchSamples, pad_idx:int=0) -> Tuple[LongTensor, LongTensor]:\n",
    "    samples = to_data(samples)\n",
    "    max_len = max([len(s[1][0]) for s in samples])\n",
    "    res_tokens = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    res_numbers = torch.zeros(len(samples),max_len, 7) - 2.0\n",
    "    for i,s in enumerate(samples):\n",
    "        res_tokens[i,:len(s[1][0])] = LongTensor(s[1][0])\n",
    "        res_numbers[i,:len(s[1][0])] = FloatTensor(s[1][1])\n",
    "    return torch.stack([s[0] for s in samples]), (res_tokens,res_numbers,torch.tensor([s[1][2] for s in samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAE = (ImageList.from_df(svgDF,path=\"\",cols=\"png\",convert_mode=\"L\")\n",
    "          .split_none()\n",
    "          .label_from_df(cols=[\"label\"],label_cls=CategoryList)\n",
    "          .transform(size=64)\n",
    "          .databunch(bs=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bs = 64\n",
    "svgDF[\"label_codes\"] = svgDF.label.apply(lambda x: dataAE.train_ds.y.c2i[x])\n",
    "data = (ImageList.from_df(svgDF,path=\"\",cols=\"png\",convert_mode=\"L\")\n",
    "        .split_none()\n",
    "        .label_from_df(cols=[\"path\",\"box_x\",\"box_y\",\"label_codes\"],label_cls=SVGList)\n",
    "        .transform(size=64)\n",
    "        .databunch(bs=bs,collate_fn=npad_collate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = collections.defaultdict(int)\n",
    "for i in range(len(data.train_ds)):\n",
    "    tokens=data.train_ds.y[i][0]\n",
    "    for t in tokens: freqs[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: 110049\n",
      "M: 153391\n",
      "q: 851017\n",
      "l: 358984\n",
      "t: 777019\n",
      "h: 318469\n",
      "z: 153391\n",
      "END: 110049\n",
      "v: 223923\n"
     ]
    }
   ],
   "source": [
    "for key in freqs.keys():\n",
    "    print(f\"{data.vocab[key]}: {freqs[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, up_in_c:int,final_div:bool=True, blur:bool=False, leaky:float=None,self_attention:bool=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, blur=blur, leaky=leaky, **kwargs)\n",
    "        ni = up_in_c//2\n",
    "        nf = ni if final_div else ni//2\n",
    "        self.conv1 = conv_layer(ni, nf, leaky=leaky, **kwargs)\n",
    "        self.conv2 = conv_layer(nf, nf, leaky=leaky, self_attention=self_attention, **kwargs)\n",
    "        self.relu = relu(leaky=leaky)\n",
    "\n",
    "    def forward(self, up_in:Tensor) -> Tensor:\n",
    "        up_out = self.shuf(up_in)\n",
    "        return self.conv2(self.conv1(up_out))\n",
    "    \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(62,16)\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv2d(1,32,5,1,2),\n",
    "            nn.InstanceNorm2d(32,affine=True),\n",
    "            nn.ReLU(),\n",
    "            conv2d(32,32,5,2,2),\n",
    "            nn.InstanceNorm2d(32,affine=True),\n",
    "            nn.ReLU(),\n",
    "            conv2d(32,64,5,1,2),\n",
    "            nn.InstanceNorm2d(64,affine=True),\n",
    "            nn.ReLU(),\n",
    "            conv2d(64,64,5,2,2),\n",
    "            nn.InstanceNorm2d(64,affine=True),\n",
    "            nn.ReLU(),\n",
    "            conv2d(64,64,3,2,1),\n",
    "            nn.InstanceNorm2d(64,affine=True),\n",
    "            nn.ReLU(),\n",
    "            conv2d(64,64,3,2,1),\n",
    "            nn.InstanceNorm2d(64,affine=True),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.z_mean = nn.Linear(64*16,32)\n",
    "        self.z_logvar = nn.Linear(64*16,32)\n",
    "        \n",
    "        self.z_to_dec = nn.Linear(32+16,128*16)\n",
    "        \n",
    "        nf = [128,64,32,16]\n",
    "        #nf = [2048,1024,512,256,128]\n",
    "        self.decoder = nn.Sequential(*[UpBlock(f, blur=(False if f != 32 else False)) for f in nf])\n",
    "        self.final_conv = conv_layer(8, 1, ks=1, use_activ=False)\n",
    "    \n",
    "    def forward(self,x,char_class):\n",
    "        u = self.encoder(x)\n",
    "        u = u.view(x.shape[0],-1)\n",
    "        mean, logvar = self.z_mean(u), self.z_logvar(u)\n",
    "        \n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mean\n",
    "        #if self.training:\n",
    "        z = z + eps*std\n",
    "            \n",
    "        z = torch.cat([z,self.emb(char_class)],dim=1)\n",
    "        ls = z\n",
    "        \n",
    "        z = self.z_to_dec(z)\n",
    "        z = z.view(x.shape[0],128,4,4)\n",
    "        \n",
    "        return torch.sigmoid(self.final_conv(self.decoder(z))), mean, logvar, ls\n",
    "        \n",
    "class VAELoss(nn.Module):\n",
    "    def forward(self, preds, target):\n",
    "        rec, mean, logvar,_ = preds\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mean.pow(2) - logvar.exp())\n",
    "        self.kld = KLD / (rec.shape[0] * 64 * 64)\n",
    "        self.bce = F.binary_cross_entropy(rec.view(rec.shape[0],-1),target.view(target.shape[0],-1))\n",
    "        return self.bce + self.kld\n",
    "\n",
    "class VAETrainer(LearnerCallback):\n",
    "    _order=-20\n",
    "    def on_train_begin(self,**kwargs):\n",
    "        self.smoothBCE, self.smoothKLD = SmoothenValue(0.98), SmoothenValue(0.98)\n",
    "        self.learn.recorder.add_metric_names([\"bce\",\"kld\"])\n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {\"last_input\": (last_input,last_target), \"last_target\": last_input}\n",
    "    \n",
    "    def on_batch_end(self,**kwargs):\n",
    "        self.smoothBCE.add_value(self.learn.loss_func.bce.item())\n",
    "        self.smoothKLD.add_value(self.learn.loss_func.kld.item())\n",
    "        \n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        return add_metrics(last_metrics,[self.smoothBCE.smooth,self.smoothKLD.smooth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAE = Learner(dataAE,VAE(),loss_func=VAELoss(),callback_fns=[VAETrainer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 03:20<00:50]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:450px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>bce</th>\n",
       "    <th>kld</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.535197</th>\n",
       "    <th>#na#</th>\n",
       "    <th>0.527670</th>\n",
       "    <th>0.007527</th>\n",
       "    <th>00:50</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.418076</th>\n",
       "    <th>#na#</th>\n",
       "    <th>0.410336</th>\n",
       "    <th>0.007740</th>\n",
       "    <th>00:50</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.404789</th>\n",
       "    <th>#na#</th>\n",
       "    <th>0.397291</th>\n",
       "    <th>0.007497</th>\n",
       "    <th>00:50</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.402462</th>\n",
       "    <th>#na#</th>\n",
       "    <th>0.395110</th>\n",
       "    <th>0.007352</th>\n",
       "    <th>00:50</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='186' class='' max='429', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      43.36% [186/429 00:22<00:29 0.4018]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnAE.fit_one_cycle(5,3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dataAE.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "learnAE.model.eval()\n",
    "rec = learnAE.model(x,y)[0]\n",
    "axes[0].imshow(x[0].permute(1,2,0).squeeze())\n",
    "axes[1].imshow(rec[0].permute(1,2,0).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONEOVERSQRT2PI = 1.0 / math.sqrt(2*math.pi)\n",
    "\n",
    "class MDN(nn.Module):\n",
    "    \"\"\"A mixture density network layer\n",
    "    The input maps to the parameters of a MoG probability distribution, where\n",
    "    each Gaussian has O dimensions and diagonal covariance.\n",
    "    Arguments:\n",
    "        in_features (int): the number of dimensions in the input\n",
    "        out_features (int): the number of dimensions in the output\n",
    "        num_gaussians (int): the number of Gaussians per output dimensions\n",
    "    Input:\n",
    "        minibatch (BxD): B is the batch size and D is the number of input\n",
    "            dimensions.\n",
    "    Output:\n",
    "        (pi, sigma, mu) (BxG, BxGxO, BxGxO): B is the batch size, G is the\n",
    "            number of Gaussians, and O is the number of dimensions for each\n",
    "            Gaussian. Pi is a multinomial distribution of the Gaussians. Sigma\n",
    "            is the standard deviation of each Gaussian. Mu is the mean of each\n",
    "            Gaussian.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, num_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.pi = nn.Sequential(\n",
    "            nn.Linear(in_features, num_gaussians),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.sigma = nn.Linear(in_features, out_features*num_gaussians)\n",
    "        self.mu = nn.Linear(in_features, out_features*num_gaussians)\n",
    "\n",
    "    def forward(self, minibatch):\n",
    "        pi = self.pi(minibatch)\n",
    "        #sigma = torch.exp(self.sigma(minibatch))\n",
    "        sigma = 0.2*torch.sigmoid(self.sigma(minibatch)) + 1e-6\n",
    "        sigma = sigma.view(-1, self.num_gaussians, self.out_features)\n",
    "        mu = self.mu(minibatch)\n",
    "        mu = mu.view(-1, self.num_gaussians, self.out_features)\n",
    "        return pi, sigma, torch.sigmoid(mu)\n",
    "\n",
    "\n",
    "def gaussian_probability(sigma, mu, data, mask):\n",
    "    \"\"\"Returns the probability of `data` given MoG parameters `sigma` and `mu`.\n",
    "    \n",
    "    Arguments:\n",
    "        sigma (BxGxO): The standard deviation of the Gaussians. B is the batch\n",
    "            size, G is the number of Gaussians, and O is the number of\n",
    "            dimensions per Gaussian.\n",
    "        mu (BxGxO): The means of the Gaussians. B is the batch size, G is the\n",
    "            number of Gaussians, and O is the number of dimensions per Gaussian.\n",
    "        data (BxI): A batch of data. B is the batch size and I is the number of\n",
    "            input dimensions.\n",
    "    Returns:\n",
    "        probabilities (BxG): The probability of each point in the probability\n",
    "            of the distribution in the corresponding sigma/mu index.\n",
    "    \"\"\"\n",
    "    data = data.unsqueeze(2).expand_as(sigma)\n",
    "    mask = mask.unsqueeze(2).expand_as(sigma)\n",
    "    ret = ONEOVERSQRT2PI * torch.exp(-0.5 * ((data - mu) / sigma)**2) / sigma\n",
    "    mask_zeros = torch.zeros_like(ret,requires_grad=False)\n",
    "    mask_zeros[mask] = 1.0\n",
    "    mask_ones = torch.ones_like(ret,requires_grad=False)\n",
    "    mask_ones[mask] = 0.0\n",
    "    #ret = mask_zeros*ret + mask_ones    \n",
    "    \n",
    "    return torch.prod(ret, 3)\n",
    "\n",
    "\n",
    "def mdn_loss(pi, sigma, mu, data, mask):\n",
    "    \"\"\"Calculates the error, given the MoG parameters and the target\n",
    "    The loss is the negative log likelihood of the data given the MoG\n",
    "    parameters.\n",
    "    \"\"\"\n",
    "    prob = pi * gaussian_probability(sigma, mu, data, mask)\n",
    "    nll = -torch.log(torch.sum(prob, dim=2)+1e-5)\n",
    "    return torch.mean(nll)\n",
    "\n",
    "\n",
    "def sample(pi, sigma, mu):\n",
    "    \"\"\"Draw samples from a MoG.\n",
    "    \"\"\"\n",
    "    categorical = torch.distributions.Categorical(pi)\n",
    "    pis = categorical.sample()\n",
    "    pis = torch.eye(12)[pis].byte()\n",
    "    normal = torch.distributions.Normal(mu[pis],sigma[pis])\n",
    "    return normal.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGDecoder(nn.Module):\n",
    "    def __init__(self,num_tokens):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(num_tokens,4)\n",
    "        self.rnn = nn.GRU(4+7+32+16,1024,4,batch_first=True,dropout=0.3)\n",
    "        self.z_to_hidden = nn.Linear(32+16,1024)\n",
    "        self.token = nn.Linear(1024,num_tokens)\n",
    "        self.pen = nn.Linear(1024,7)\n",
    "        \n",
    "    def get_preds(self, z):\n",
    "        hs = self.z_to_hidden(z).unsqueeze(0).expand(4,-1,-1).contiguous()\n",
    "        tools = [21]\n",
    "        pens = [torch.zeros(7).fill_(-2.0).cuda()]\n",
    "        i = 0\n",
    "        while i < 50 and tools[-1] != 22:\n",
    "            r_in = torch.cat([self.token_emb(torch.tensor([[tools[-1]]]).cuda()),pens[-1][None,None,:],z[None,None,:]],dim=2)\n",
    "            output, hs = self.rnn(r_in,hs)\n",
    "            tool = self.token(output)\n",
    "            pen = self.pen(output)\n",
    "            tools.append(torch.argmax(tool[0,0]).item())\n",
    "            pens.append(pen[0,0])\n",
    "            \n",
    "        return tools, pens\n",
    "        \n",
    "    def forward(self, tokens, pen, z):\n",
    "        tokens = self.token_emb(tokens)\n",
    "        hs = self.z_to_hidden(z).unsqueeze(0).expand(4,-1,-1).contiguous()\n",
    "        #print(tokens.shape,pen.shape,z.shape)\n",
    "        r_in = torch.cat([tokens,pen,z.unsqueeze(1).expand(-1,tokens.shape[1],-1)],dim=2)\n",
    "        output, hs = self.rnn(r_in,hs)\n",
    "        \n",
    "        tokens = self.token(output)\n",
    "        pen = self.pen(output)\n",
    "        \n",
    "        return tokens, pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svg_decoder_loss(preds,target_tokens,target_pen):\n",
    "    tokens, pen = preds\n",
    "    loss_token = F.cross_entropy(tokens.transpose(1,2)[:,:,:-1],target_tokens)\n",
    "    loss_pen = F.mse_loss(pen[:,:-1],target_pen)\n",
    "    return loss_token + loss_pen\n",
    "\n",
    "class SVGDecoderTrainer(LearnerCallback):\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        learnAE.model.train()\n",
    "        _,_,_,z = learnAE.model(last_input,last_target[2])\n",
    "        return {\"last_input\": (last_target[0],last_target[1],z), \"last_target\": (last_target[0][:,1:],last_target[1][:,1:])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnSVG = Learner(data,SVGDecoder(len(data.vocab)),loss_func=svg_decoder_loss,callback_fns=[SVGDecoderTrainer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [1/5 05:03<20:15]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.521634</th>\n",
       "    <th>#na#</th>\n",
       "    <th>05:03</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='3439', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-c2b28fbb44fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearnSVG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_bwd\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learnSVG.fit_one_cycle(5,3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnSVG.save(\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_path(x,labels):\n",
    "    z = learnAE.model(x,labels)[3]\n",
    "    tools, pens = learnSVG.model.get_preds(z[0])\n",
    "    out = []\n",
    "    for t,p in zip(tools[1:-1],pens[1:-1]):\n",
    "        t = data.vocab[t]\n",
    "        out.append(t)\n",
    "        out.append(\" \".join([str(n.item()) for n in p[:len(tool_dict[t])]]))\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M 0.5152388215065002 0.2084828019142151 v -0.05968243628740311 l -0.0025526657700538635 -0.783219575881958 h -0.04566347599029541 v 0.06888554245233536 h 0.14880821108818054 v 0.06995179504156113 l 0.05992767959833145 -0.7451941967010498 h 0.10162000358104706 v -0.09506947547197342 h -0.12045013904571533 z '"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = get_pred_path(x[[0]],y[[0]])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAQAAABpN6lAAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QAAKqNIzIAAAAHdElNRQfjCAgQNBVjERTOAAABG0lEQVR42u3UPU/CUABG4UNbBMpHBQT+/w9ydnZ3dnDR5drUGBM74BvLecYOzXtPbu4MgHduVpUekGaA9IA0A6QHpBkgPSDNAOkBaQZID0gzQHpAmgHSA9IMkB6QZoD0gDQDpAekGSA9IM0A6QFpNx+gBuCNR5545oVXKtr0qL80++FrRUXDnAULlqxYs2bDjo6OPQeOPHDiTJc+wHUCjPtDRT2I1dKyYcuWjvsvsTbpw14nwNhYTR9rxYr1INahxDpzZjnNAOOW1dTM+1htibUrN+tYYl1ophlgjKrcrLvyYg1j7UusEycu3887jQC/N+tv1mcsSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSZIkSdI/8AEsrQvR2h1ywgAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxOS0wOC0wOFQxNjo1MjoyMSswMDowMAK60dgAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTktMDgtMDhUMTY6NTI6MjErMDA6MDBz52lkAAAASnRFWHRzaWduYXR1cmUANWU2NzQ2Y2ZkZjVhODY2MTc4OTRlMzA1MjRiOGRjZjdmZmZjYjM1ZGVhZmVhYjhiOWRhM2U0YzRkYTBjNzBkMhWPBxMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<wand.image.Image: 5e6746c 'SVG' (128x128)>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_path(p,1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
